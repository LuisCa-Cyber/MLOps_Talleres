{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe57fbb-a739-4451-9354-99fa127b176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe1c9ea-5b8b-4998-8a79-e231ae6c11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98a1b7c-4a58-43f0-a4a2-f6b1c3621825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear la conexi√≥n a la base de datos MySQL\n",
    "db_uri = \"mysql+pymysql://root:supersecret@10.43.101.172:3306/training_data\"\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Cargar datos desde archivos CSV en lugar de MySQL\n",
    "# ---------------------------------------------------------\n",
    "# Para el primer conjunto (datos del archivo penguins_Iter.csv)\n",
    "df1 = pd.read_csv('/home/jovyan/work/penguins_lter.csv', sep=\",\")  # Reemplaza con la ruta correcta\n",
    "\n",
    "# Para el segundo conjunto (datos del archivo penguins_size.csv)\n",
    "df2 = pd.read_csv('/home/jovyan/work/penguins_size.csv', sep=\",\")  # Reemplaza con la ruta correcta\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Escribir los DataFrames en la base de datos (si las tablas no existen)\n",
    "# ---------------------------------------------------------\n",
    "df1.to_sql('raw_penguins_lter', con=engine, if_exists='replace', index=False)\n",
    "df2.to_sql('raw_penguins_size', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0aad77-f0cb-4ce1-89c2-554d8c156bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyName</th>\n",
       "      <th>Sample Number</th>\n",
       "      <th>Species</th>\n",
       "      <th>Region</th>\n",
       "      <th>Island</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Individual ID</th>\n",
       "      <th>Clutch Completion</th>\n",
       "      <th>Date Egg</th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <th>Body Mass (g)</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Delta 15 N (o/oo)</th>\n",
       "      <th>Delta 13 C (o/oo)</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>1</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N1A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/11/07</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not enough blood for isotopes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>2</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N1A2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/11/07</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.94956</td>\n",
       "      <td>-24.69454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>3</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N2A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/16/07</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.36821</td>\n",
       "      <td>-25.33302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>4</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N2A2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/16/07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult not sampled.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>5</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N3A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/16/07</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.76651</td>\n",
       "      <td>-25.32426</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  studyName  Sample Number                              Species  Region  \\\n",
       "0   PAL0708              1  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "1   PAL0708              2  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "2   PAL0708              3  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "3   PAL0708              4  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "4   PAL0708              5  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "\n",
       "      Island               Stage Individual ID Clutch Completion  Date Egg  \\\n",
       "0  Torgersen  Adult, 1 Egg Stage          N1A1               Yes  11/11/07   \n",
       "1  Torgersen  Adult, 1 Egg Stage          N1A2               Yes  11/11/07   \n",
       "2  Torgersen  Adult, 1 Egg Stage          N2A1               Yes  11/16/07   \n",
       "3  Torgersen  Adult, 1 Egg Stage          N2A2               Yes  11/16/07   \n",
       "4  Torgersen  Adult, 1 Egg Stage          N3A1               Yes  11/16/07   \n",
       "\n",
       "   Culmen Length (mm)  Culmen Depth (mm)  Flipper Length (mm)  Body Mass (g)  \\\n",
       "0                39.1               18.7                181.0         3750.0   \n",
       "1                39.5               17.4                186.0         3800.0   \n",
       "2                40.3               18.0                195.0         3250.0   \n",
       "3                 NaN                NaN                  NaN            NaN   \n",
       "4                36.7               19.3                193.0         3450.0   \n",
       "\n",
       "      Sex  Delta 15 N (o/oo)  Delta 13 C (o/oo)  \\\n",
       "0    MALE                NaN                NaN   \n",
       "1  FEMALE            8.94956          -24.69454   \n",
       "2  FEMALE            8.36821          -25.33302   \n",
       "3     NaN                NaN                NaN   \n",
       "4  FEMALE            8.76651          -25.32426   \n",
       "\n",
       "                         Comments  \n",
       "0  Not enough blood for isotopes.  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3              Adult not sampled.  \n",
       "4                             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2f8077-80ed-426c-b6ef-d51ded464460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos combinados y procesados:\n",
      "                               species  island  culmen_length_mm  \\\n",
      "0  Adelie Penguin (Pygoscelis adeliae)       2              39.1   \n",
      "1  Adelie Penguin (Pygoscelis adeliae)       2              39.5   \n",
      "2  Adelie Penguin (Pygoscelis adeliae)       2              40.3   \n",
      "3  Adelie Penguin (Pygoscelis adeliae)       2              36.7   \n",
      "4  Adelie Penguin (Pygoscelis adeliae)       2              39.3   \n",
      "\n",
      "   culmen_depth_mm  flipper_length_mm  body_mass_g  sex  \n",
      "0             18.7              181.0       3750.0    1  \n",
      "1             17.4              186.0       3800.0    0  \n",
      "2             18.0              195.0       3250.0    0  \n",
      "3             19.3              193.0       3450.0    0  \n",
      "4             20.6              190.0       3650.0    1  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Limpieza de datos: reemplazar valores indeseados y eliminar registros faltantes\n",
    "# ---------------------------------------------------------\n",
    "# En ambos DataFrames la columna de sexo viene almacenada como \"sex\"\n",
    "df1[\"Sex\"] = df1[\"Sex\"].replace({\".\": None})\n",
    "df2[\"sex\"] = df2[\"sex\"].replace({\".\": None})\n",
    "\n",
    "# Eliminar registros con valores faltantes en la columna \"sex\"\n",
    "df1_clean = df1.dropna(subset=[\"Sex\"])\n",
    "df2_clean = df2.dropna(subset=[\"sex\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Renombrar columnas (si es necesario) y seleccionar las columnas de inter√©s\n",
    "\n",
    "df1_clean = df1_clean.rename(columns={\n",
    "    \"Species\": \"species\",\n",
    "    \"Island\": \"island\",\n",
    "    \"Culmen Length (mm)\": \"culmen_length_mm\",\n",
    "    \"Culmen Depth (mm)\": \"culmen_depth_mm\",\n",
    "    \"Flipper Length (mm)\": \"flipper_length_mm\",\n",
    "    \"Body Mass (g)\": \"body_mass_g\",\n",
    "    \"Sex\": \"sex\"\n",
    "})\n",
    "df1_clean = df1_clean[[\"species\", \"island\", \"culmen_length_mm\", \"culmen_depth_mm\",\n",
    "                       \"flipper_length_mm\", \"body_mass_g\", \"sex\"]]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Combinar ambos DataFrames\n",
    "# ---------------------------------------------------------\n",
    "df_combined = pd.concat([df1_clean, df2_clean], ignore_index=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Mapear la variable 'sex': MALE -> 1, FEMALE -> 0\n",
    "# ---------------------------------------------------------\n",
    "df_combined[\"sex\"] = df_combined[\"sex\"].map({\"MALE\": 1, \"FEMALE\": 0})\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Codificar la variable categ√≥rica \"island\"\n",
    "# ---------------------------------------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "df_combined[\"island\"] = label_encoder.fit_transform(df_combined[\"island\"])\n",
    "\n",
    "print(\"Datos combinados y procesados:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456dec61-7eb3-4efd-b36e-0c5efae76959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados guardados en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "# Conexi√≥n a la base de datos MySQL\n",
    "\n",
    "db_uri = \"mysql+pymysql://root:supersecret@10.43.101.172:3306/training_data\"\n",
    "engine = sqlalchemy.create_engine(db_uri)\n",
    "\n",
    "# Guardar el DataFrame en una tabla (se reemplaza la tabla si ya existe)\n",
    "df_combined.to_sql('processed_penguins', engine, if_exists='replace', index=False)\n",
    "print(\"Datos procesados guardados en la base de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31274fee-0c2b-4c8f-8f64-378427ecc1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos divididos en entrenamiento y prueba.\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las caracter√≠sticas y la variable objetivo\n",
    "X = df_combined[[\"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"island\"]]\n",
    "y = df_combined[\"sex\"]\n",
    "\n",
    "# Normalizar las caracter√≠sticas utilizando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Datos divididos en entrenamiento y prueba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dca4a51-8086-426c-9431-d6978c132f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/15 05:28:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/15 05:28:09 INFO mlflow.tracking.fluent: Experiment with name 'PenguinClassification' does not exist. Creating a new experiment.\n",
      "2025/03/15 05:28:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/03/15 05:28:11 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: No module named 'boto3'\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "\u001b[31m2025/03/15 05:28:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Experiment 0 at: http://10.43.101.172:5000/#/experiments/1/runs/898144fefa2c4288af2d1f687dbf6e3c\n",
      "üß™ View experiment at: http://10.43.101.172:5000/#/experiments/1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Registrar el modelo en MLflow: se usar√° el nombre registrado seg√∫n el tipo de modelo.\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Modelo = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acc \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:413\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m    336\u001b[0m     sk_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ):\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    containing the following flavors:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/models/model.py:932\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m    930\u001b[0m         client\u001b[38;5;241m.\u001b[39mlog_prompt(run_id, prompt)\n\u001b[0;32m--> 932\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/tracking/fluent.py:1219\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path, run_id)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m-> 1219\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/tracking/client.py:2426\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_artifacts\u001b[39m(\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m, artifact_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   2383\u001b[0m \n\u001b[1;32m   2384\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \n\u001b[1;32m   2425\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:959\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_dir, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    951\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:184\u001b[0m, in \u001b[0;36mS3ArtifactRepository.log_artifacts\u001b[0;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artifact_path:\n\u001b[1;32m    183\u001b[0m     dest_path \u001b[38;5;241m=\u001b[39m posixpath\u001b[38;5;241m.\u001b[39mjoin(dest_path, artifact_path)\n\u001b[0;32m--> 184\u001b[0m s3_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_s3_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m local_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_dir)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(local_dir):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:135\u001b[0m, in \u001b[0;36mS3ArtifactRepository._get_s3_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_s3_client\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_s3_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_key_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_access_key_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43msecret_access_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_secret_access_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:110\u001b[0m, in \u001b[0;36m_get_s3_client\u001b[0;34m(addressing_style, access_key_id, secret_access_key, session_token, region_name, s3_endpoint_url)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m addressing_style:\n\u001b[1;32m    108\u001b[0m     addressing_style \u001b[38;5;241m=\u001b[39m MLFLOW_BOTO_CLIENT_ADDRESSING_STYLE\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cached_get_s3_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddressing_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_endpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccess_key_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccess_key_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecret_access_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecret_access_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:59\u001b[0m, in \u001b[0;36m_cached_get_s3_client\u001b[0;34m(signature_version, addressing_style, s3_endpoint_url, verify, timestamp, access_key_id, secret_access_key, session_token, region_name)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_cached_get_s3_client\u001b[39m(\n\u001b[1;32m     36\u001b[0m     signature_version,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a boto3 client, caching to avoid extra boto3 verify calls.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    This method is outside of the S3ArtifactRepository as it is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    we utilise the `timestamp` parameter to invalidate cache.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Making it possible to access public S3 buckets\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Workaround for https://github.com/boto/botocore/issues/2442\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "# Conectar al servidor de MLflow y habilitar el autologging\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.172:5000\")\n",
    "mlflow.autolog()  # Esto activa el autologging para modelos, par√°metros, m√©tricas y artefactos en las librer√≠as compatibles\n",
    "\n",
    "# Lista de modelos a usar\n",
    "model_names = [\"random_forest\", \"decision_tree\", \"svm\", \"logistic_regression\"]\n",
    "\n",
    "# Configurar el experimento en MLflow\n",
    "experiment_name = \"PenguinClassification\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_run_id = None\n",
    "\n",
    "# Realizar 20 experimentos\n",
    "for i in range(20):\n",
    "    with mlflow.start_run(run_name=f\"Experiment {i}\") as run:\n",
    "        \n",
    "        # Seleccionar de forma aleatoria un modelo\n",
    "        model_type = random.choice(model_names)\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        \n",
    "        # Definir y registrar hiperpar√°metros dependiendo del modelo\n",
    "        if model_type == \"random_forest\":\n",
    "            n_estimators = random.randint(50, 150)\n",
    "            max_depth_val = random.choice([None, 3, 5, 7, 10])\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"max_depth\", max_depth_val)\n",
    "            # Inicializar RandomForest\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                           max_depth=max_depth_val, \n",
    "                                           random_state=42)\n",
    "            \n",
    "        elif model_type == \"decision_tree\":\n",
    "            max_depth_val = random.choice([None, 3, 5, 7, 10])\n",
    "            min_samples_split = random.randint(2, 10)\n",
    "            mlflow.log_param(\"max_depth\", max_depth_val)\n",
    "            mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "            # Inicializar DecisionTree\n",
    "            model = DecisionTreeClassifier(max_depth=max_depth_val, \n",
    "                                           min_samples_split=min_samples_split, \n",
    "                                           random_state=42)\n",
    "            \n",
    "        elif model_type == \"svm\":\n",
    "            C_val = round(random.uniform(0.1, 10), 2)\n",
    "            kernel_val = random.choice([\"linear\", \"rbf\"])\n",
    "            mlflow.log_param(\"C\", C_val)\n",
    "            mlflow.log_param(\"kernel\", kernel_val)\n",
    "            # Inicializar SVC; en este caso usar probability=True si se requiere obtener probabilidades\n",
    "            model = SVC(C=C_val, kernel=kernel_val, random_state=42, probability=True)\n",
    "            \n",
    "        elif model_type == \"logistic_regression\":\n",
    "            C_val = round(random.uniform(0.1, 10), 2)\n",
    "            penalty = random.choice(['l1', 'l2'])\n",
    "            # Para penalty 'l1' se debe usar un solver compatible como \"liblinear\"\n",
    "            solver = \"liblinear\" if penalty == 'l1' else \"lbfgs\"\n",
    "            mlflow.log_param(\"C\", C_val)\n",
    "            mlflow.log_param(\"penalty\", penalty)\n",
    "            mlflow.log_param(\"solver\", solver)\n",
    "            # Inicializar LogisticRegression\n",
    "            model = LogisticRegression(C=C_val, penalty=penalty, solver=solver, random_state=42, max_iter=1000)\n",
    "        \n",
    "        # Entrenar el modelo seleccionado\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Crear un pipeline que incluya el escalador y el modelo ya entrenado\n",
    "        pipeline = Pipeline(steps=[('scaler', scaler), ('model', model)])\n",
    "        \n",
    "        # Evaluar el desempe√±o en el conjunto de prueba\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        \n",
    "        # Registrar el modelo en MLflow: se usar√° el nombre registrado seg√∫n el tipo de modelo.\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_type\n",
    "        )\n",
    "        \n",
    "        print(f\"Run {i}: Modelo = {model_type}, Accuracy = {acc:.4f}\")\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_run_id = run.info.run_id\n",
    "\n",
    "print(f\"Mejor ejecuci√≥n: {best_run_id} con accuracy = {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5b60f-8e85-4483-89ed-d321e76282da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
